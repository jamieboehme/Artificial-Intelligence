{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":39224,"status":"ok","timestamp":1669237349568,"user":{"displayName":"Jamie Boehme","userId":"02276919821827120520"},"user_tz":360},"id":"AWsN_e7cm0jI","outputId":"98be2c04-34ec-45f1-858e-389245f38205"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","Cloning into 'keras-deeplab-v3-plus'...\n","remote: Enumerating objects: 375, done.\u001b[K\n","remote: Total 375 (delta 0), reused 0 (delta 0), pack-reused 375\u001b[K\n","Receiving objects: 100% (375/375), 5.12 MiB | 8.55 MiB/s, done.\n","Resolving deltas: 100% (202/202), done.\n","/content/keras-deeplab-v3-plus\n","Found 607 images belonging to 30 classes.\n","Found 607 images belonging to 30 classes.\n","Found 607 images belonging to 30 classes.\n","Found 187 images belonging to 30 classes.\n","Found 187 images belonging to 30 classes.\n"]}],"source":["# University of St Thomas \n","# SEIS 764 AI Fall 2022, Prof. Chih Lai\n","#\n","# TEAM PROJECT\n","#\n","# Jamie Boehme\n","# Jonathan Ditlevson\n","# Satya Dampanaboyina\n","# Swetha Doddi\n","# Stan Kegel\n","#\n","# INITIAL STRAWMAN VERSION - 06-NOV-2022 - stan_20221106v1.ipynb\n","#\n","# WORK IN PROGRESS COMMENTARY...\n","#\n","# PROBLEMS / MYSTERIES\n","# 1) Why does accuracy obtained with predict method on validation/test data not \n","#    agree with validation accuracy reported during fit epoch?? (This problem has\n","#    been seen both with and without checkpointing the model.)\n","#\n","# HOPEFUL IMPROVEMENT IDEAS [To Try Next]:\n","# 1)  Use improved image set, with fewer discarded images from baseline set.  (Jon has been working on that.)\n","#     A few more imagees might make a big difference.\n","# 2)  Look at any ideas found / researched by other team members since kick-off meeting\n","# 3)  Use better pre-trained CNN srchitecture, tuned to handle images with multiple granularities of interest \n","#     (It looks like Inception-Network may fit the )\n","#     -- Ref. https://towardsdatascience.com/a-simple-guide-to-the-versions-of-the-inception-network-7fc52b863202\n","#     NOTE: Don't forget to change preprocessing function when changing pre-learned model!  (SEE IMPORT STATEMENT \n","#     FOR \"preporcess_input\" NEAR TOP OF NOTEBOOK.)\n","# 4)  Look at adding Regularization -- add regularizer to dense layers, add drop out regularization layers\n","#     -- Ref. https://jinwen17.medium.com/tricks-to-prevent-overfitting-in-cnn-model-trained-on-a-small-dataset-b84f05eb4eb7\n","#   \n","# SUBSEQUENT LIKELY IMPROVEMENTS [Later / After we hopefully get accuracy in the 90s]:\n","# 1)  Fine Tuning (Unfreezing a few layers of pre-trained CNN) \n","#     - Ref: https://keras.io/guides/transfer_learning/\n","#     - Ref. https://www.tensorflow.org/guide/keras/transfer_learning\n","# 2)  Consider adding \"Early Stopping\"\n","#\n","# OTHER POSSIBLE IMPROVEMENT IDEAS:\n","# 1)  Experiment with optimizer functions, learning rate, momentum (shouldn't it be called inertia?), \n","#     learning rate decay, and batch size.  (already tried this to some extent)\n","#     -- Ref. https://keras.io/api/optimizers/\n","# 2)  Look into image/pixel normalization\n","#     -- Ref. https://machinelearningmastery.com/how-to-normalize-center-and-standardize-images-with-the-imagedatagenerator-in-keras/\n","#     -- Ref. https://theailearner.com/2019/07/06/keras-imagedatagenerator-normalization-at-validation-and-test-time/#\n","# 3)  Experiment with augmentation options (already tried this to some extent)\n","#\n","# SPECULATIVE/DESPERATE [Probably less fruitful] IMPROVEMENT IDEAS:\n","# 1)  Try a custom CNN with larger image area ingestion (and simpler design) \n","# 2)  Try multiple models / ensemble voting (oof-da)\n","#\n","\n","from datetime import datetime\n","from tensorflow import keras\n","from keras import Sequential\n","from keras.layers import Conv2D, Dense, Flatten, Activation, Dropout, Flatten, MaxPooling2D, BatchNormalization, GlobalAveragePooling2D\n","from keras.losses import CategoricalCrossentropy\n","from keras.preprocessing.image import ImageDataGenerator\n","import numpy as np\n","from sklearn.metrics import accuracy_score\n","from sklearn.metrics import confusion_matrix\n","#from keras.applications.vgg19 import preprocess_input\n","from keras.applications.inception_v3 import preprocess_input\n","#from keras.applications.inception_resnet_v2 import preprocess_input\n","#from keras.applications.resnet import preprocess_input\n","from PIL import Image\n","from torchvision import transforms\n","\n","# parameters for image data \n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","dir_path = \"/content/drive/My Drive/Crops\"\n","\n","\n","img_class_mode_ = 'categorical'\n","rotation_range_ = 10       # 15 degrees rotation range for image augmentation\n","width_shift_range_ = 0.1  # 15% horizontal shift range for image augmentation\n","height_shift_range_ = 0.1 # 15% pixels veritcal shift range for image augmentation\n","zoom_range_ = 0.3          # zoom range 0.7 - 1.3 for image augmentation\n","brightness_range_ = (0.3, 0.8)   # brightness range 50% to 100% for image augmentation\n","horizontal_flip_ = True    # horizontal flip on for image augmentation\n","interpolation_mode_ = \"lanczos\"  # higher quality interpolation for re-scaling (when applicable)\n","fill_mode_ = \"reflect\"  # reflect margin for shifted regions for image augmentation\n","keep_aspect_ratio_ = True\n","\n","# parameters for learning\n","img_batch_size_ = 10 \n","checkpoint_path = \"model_checkpoint_\" + datetime.now().strftime('%Y%m%d-%H%M%S') + \".h5\"\n","\n","# fix model.py: Line #170 in_channels = inputs.shape[-1]\n","!git clone https://github.com/rkuo2000/keras-deeplab-v3-plus \n","%cd keras-deeplab-v3-plus\n","\n","\n","# load data and split into training and test/validation data sets\n","images_data = ImageDataGenerator(\n","    rescale=1. / 255, \n","    preprocessing_function = preprocess_input,  # Ref. https://keras.io/api/applications/vgg/#vgg19-function\n","    validation_split = 0.25,\n","    rotation_range = rotation_range_, width_shift_range = width_shift_range_,\n","    height_shift_range = height_shift_range_, zoom_range = zoom_range_,\n","    horizontal_flip = horizontal_flip_, fill_mode = fill_mode_, \n","    brightness_range = brightness_range_)\n","trainD_shuffle = images_data.flow_from_directory(\n","    dir_path, shuffle = True, target_size = (299, 299), interpolation = interpolation_mode_,\n","    keep_aspect_ratio = keep_aspect_ratio_,\n","    class_mode = img_class_mode_, batch_size = img_batch_size_, subset = 'training')\n","trainD_mask = images_data.flow_from_directory(\n","    dir_path, shuffle = True, target_size = (299, 299), interpolation = interpolation_mode_,\n","    keep_aspect_ratio = keep_aspect_ratio_,\n","    class_mode = img_class_mode_, batch_size = img_batch_size_, subset = 'training')\n","trainD_noshuffle = images_data.flow_from_directory(\n","    dir_path, shuffle = False, target_size = (299, 299), interpolation = interpolation_mode_,\n","    keep_aspect_ratio = keep_aspect_ratio_,    \n","    class_mode = img_class_mode_, batch_size = img_batch_size_, subset = 'training')\n","testD_noshuffle = images_data.flow_from_directory(\n","    dir_path, shuffle = False, target_size = (299, 299), interpolation = interpolation_mode_,\n","    keep_aspect_ratio = keep_aspect_ratio_,\n","    class_mode = img_class_mode_, batch_size = img_batch_size_, subset = 'validation')\n","testD_mask = images_data.flow_from_directory(\n","    dir_path, shuffle = False, target_size = (299, 299), interpolation = interpolation_mode_,\n","    keep_aspect_ratio = keep_aspect_ratio_,\n","    class_mode = img_class_mode_, batch_size = img_batch_size_, subset = 'validation')\n"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1669237349568,"user":{"displayName":"Jamie Boehme","userId":"02276919821827120520"},"user_tz":360},"id":"7Qk-6AEjnHkm","outputId":"75f306cd-e1ef-4fbd-af8b-897e6dd675ab"},"outputs":[{"output_type":"stream","name":"stdout","text":["image class count 30\n"]}],"source":["train_img_class_count = len(trainD_noshuffle.class_indices)\n","test_img_class_count = len(testD_noshuffle.class_indices)\n","if (train_img_class_count != test_img_class_count):\n","    raise Exception(\"Training and Testing Data Sets Not Aligned.\")\n","img_class_count = test_img_class_count\n","print(\"image class count\", img_class_count)"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":8391,"status":"ok","timestamp":1669237357946,"user":{"displayName":"Jamie Boehme","userId":"02276919821827120520"},"user_tz":360},"id":"cRnBDsni5pwu","colab":{"base_uri":"https://localhost:8080/"},"outputId":"8f056661-5c0b-4617-9d36-e0b6e6bed986"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n","87910968/87910968 [==============================] - 3s 0us/step\n"]}],"source":["# get pre-trained CNN\n","#from keras.applications import InceptionResNetV2\n","from keras.applications import InceptionV3\n","#from keras.applications import ResNet50V2\n","cnn = InceptionV3(weights = 'imagenet', include_top = False, input_shape = (299, 299, 3))\n","cnn.trainable = False"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":714,"status":"ok","timestamp":1669237358644,"user":{"displayName":"Jamie Boehme","userId":"02276919821827120520"},"user_tz":360},"id":"KKhCLoqM5C6d"},"outputs":[],"source":["opt = keras.optimizers.Adam(learning_rate=0.0001)\n","epochs_ = 150\n","\n","model = Sequential([\n","    cnn,\n","    Flatten(),\n","    Dense(360, activation = 'relu'),\n","    Dense(180, activation = 'relu'),\n","    Dropout(.25),\n","    Dense(90, activation = 'relu'),\n","    Dropout(.2),\n","    Dense(img_class_count, activation = 'softmax')\n","])\n","\n","model.compile(loss = CategoricalCrossentropy(), \n","    optimizer=opt, \n","     metrics = ['accuracy'])"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1669237358645,"user":{"displayName":"Jamie Boehme","userId":"02276919821827120520"},"user_tz":360},"id":"jaG0MoaqwgrE","outputId":"4954aeb9-a9fb-47fe-e332-c2d955276f77"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," inception_v3 (Functional)   (None, 8, 8, 2048)        21802784  \n","                                                                 \n"," flatten (Flatten)           (None, 131072)            0         \n","                                                                 \n"," dense (Dense)               (None, 360)               47186280  \n","                                                                 \n"," dense_1 (Dense)             (None, 180)               64980     \n","                                                                 \n"," dropout (Dropout)           (None, 180)               0         \n","                                                                 \n"," dense_2 (Dense)             (None, 90)                16290     \n","                                                                 \n"," dropout_1 (Dropout)         (None, 90)                0         \n","                                                                 \n"," dense_3 (Dense)             (None, 30)                2730      \n","                                                                 \n","=================================================================\n","Total params: 69,073,064\n","Trainable params: 47,270,280\n","Non-trainable params: 21,802,784\n","_________________________________________________________________\n"]}],"source":["model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-MinzcR-nIKo","outputId":"35eb4413-2ead-45d0-d06f-af6053f15006"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/150\n"," 4/61 [>.............................] - ETA: 3:06 - loss: 4.0991 - accuracy: 0.0000e+00"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 11 bytes but only got 10. Skipping tag 42037\n","  \" Skipping tag %s\" % (size, len(data), tag)\n"]},{"output_type":"stream","name":"stdout","text":["61/61 [==============================] - ETA: 0s - loss: 3.6557 - accuracy: 0.0329\n","Epoch 1: val_accuracy improved from -inf to 0.03743, saving model to model_checkpoint_20221123-210224.h5\n","61/61 [==============================] - 369s 6s/step - loss: 3.6557 - accuracy: 0.0329 - val_loss: 3.4409 - val_accuracy: 0.0374\n","Epoch 2/150\n","61/61 [==============================] - ETA: 0s - loss: 3.4911 - accuracy: 0.0297\n","Epoch 2: val_accuracy improved from 0.03743 to 0.05348, saving model to model_checkpoint_20221123-210224.h5\n","61/61 [==============================] - 35s 578ms/step - loss: 3.4911 - accuracy: 0.0297 - val_loss: 3.4140 - val_accuracy: 0.0535\n","Epoch 3/150\n","61/61 [==============================] - ETA: 0s - loss: 3.4562 - accuracy: 0.0445\n","Epoch 3: val_accuracy did not improve from 0.05348\n","61/61 [==============================] - 30s 491ms/step - loss: 3.4562 - accuracy: 0.0445 - val_loss: 3.3932 - val_accuracy: 0.0481\n","Epoch 4/150\n","61/61 [==============================] - ETA: 0s - loss: 3.4465 - accuracy: 0.0362\n","Epoch 4: val_accuracy did not improve from 0.05348\n","61/61 [==============================] - 31s 511ms/step - loss: 3.4465 - accuracy: 0.0362 - val_loss: 3.4018 - val_accuracy: 0.0481\n","Epoch 5/150\n","61/61 [==============================] - ETA: 0s - loss: 3.4334 - accuracy: 0.0445\n","Epoch 5: val_accuracy did not improve from 0.05348\n","61/61 [==============================] - 31s 508ms/step - loss: 3.4334 - accuracy: 0.0445 - val_loss: 3.3864 - val_accuracy: 0.0428\n","Epoch 6/150\n","61/61 [==============================] - ETA: 0s - loss: 3.4050 - accuracy: 0.0313\n","Epoch 6: val_accuracy did not improve from 0.05348\n","61/61 [==============================] - 30s 486ms/step - loss: 3.4050 - accuracy: 0.0313 - val_loss: 3.3935 - val_accuracy: 0.0374\n","Epoch 7/150\n","61/61 [==============================] - ETA: 0s - loss: 3.4068 - accuracy: 0.0379\n","Epoch 7: val_accuracy did not improve from 0.05348\n","61/61 [==============================] - 32s 531ms/step - loss: 3.4068 - accuracy: 0.0379 - val_loss: 3.4009 - val_accuracy: 0.0374\n","Epoch 8/150\n","61/61 [==============================] - ETA: 0s - loss: 3.4010 - accuracy: 0.0329\n","Epoch 8: val_accuracy did not improve from 0.05348\n","61/61 [==============================] - 31s 507ms/step - loss: 3.4010 - accuracy: 0.0329 - val_loss: 3.4007 - val_accuracy: 0.0428\n","Epoch 9/150\n","61/61 [==============================] - ETA: 0s - loss: 3.4009 - accuracy: 0.0428\n","Epoch 9: val_accuracy did not improve from 0.05348\n","61/61 [==============================] - 30s 486ms/step - loss: 3.4009 - accuracy: 0.0428 - val_loss: 3.4006 - val_accuracy: 0.0428\n","Epoch 10/150\n","61/61 [==============================] - ETA: 0s - loss: 3.4008 - accuracy: 0.0395\n","Epoch 10: val_accuracy did not improve from 0.05348\n","61/61 [==============================] - 31s 502ms/step - loss: 3.4008 - accuracy: 0.0395 - val_loss: 3.4005 - val_accuracy: 0.0481\n","Epoch 11/150\n","61/61 [==============================] - ETA: 0s - loss: 3.4012 - accuracy: 0.0494\n","Epoch 11: val_accuracy did not improve from 0.05348\n","61/61 [==============================] - 31s 509ms/step - loss: 3.4012 - accuracy: 0.0494 - val_loss: 3.4004 - val_accuracy: 0.0481\n","Epoch 12/150\n","61/61 [==============================] - ETA: 0s - loss: 3.4026 - accuracy: 0.0395\n","Epoch 12: val_accuracy did not improve from 0.05348\n","61/61 [==============================] - 32s 533ms/step - loss: 3.4026 - accuracy: 0.0395 - val_loss: 3.4003 - val_accuracy: 0.0481\n","Epoch 13/150\n","61/61 [==============================] - ETA: 0s - loss: 3.4006 - accuracy: 0.0461\n","Epoch 13: val_accuracy did not improve from 0.05348\n","61/61 [==============================] - 30s 495ms/step - loss: 3.4006 - accuracy: 0.0461 - val_loss: 3.4001 - val_accuracy: 0.0481\n","Epoch 14/150\n","61/61 [==============================] - ETA: 0s - loss: 3.4004 - accuracy: 0.0461\n","Epoch 14: val_accuracy did not improve from 0.05348\n","61/61 [==============================] - 30s 497ms/step - loss: 3.4004 - accuracy: 0.0461 - val_loss: 3.4000 - val_accuracy: 0.0481\n","Epoch 15/150\n","61/61 [==============================] - ETA: 0s - loss: 3.4003 - accuracy: 0.0428\n","Epoch 15: val_accuracy did not improve from 0.05348\n","61/61 [==============================] - 30s 488ms/step - loss: 3.4003 - accuracy: 0.0428 - val_loss: 3.3999 - val_accuracy: 0.0481\n","Epoch 16/150\n","61/61 [==============================] - ETA: 0s - loss: 3.4001 - accuracy: 0.0511\n","Epoch 16: val_accuracy did not improve from 0.05348\n","61/61 [==============================] - 28s 466ms/step - loss: 3.4001 - accuracy: 0.0511 - val_loss: 3.3997 - val_accuracy: 0.0481\n","Epoch 17/150\n","61/61 [==============================] - ETA: 0s - loss: 3.4001 - accuracy: 0.0461\n","Epoch 17: val_accuracy did not improve from 0.05348\n","61/61 [==============================] - 30s 491ms/step - loss: 3.4001 - accuracy: 0.0461 - val_loss: 3.3996 - val_accuracy: 0.0481\n","Epoch 18/150\n","61/61 [==============================] - ETA: 0s - loss: 3.3998 - accuracy: 0.0461\n","Epoch 18: val_accuracy did not improve from 0.05348\n","61/61 [==============================] - 32s 526ms/step - loss: 3.3998 - accuracy: 0.0461 - val_loss: 3.3994 - val_accuracy: 0.0481\n","Epoch 19/150\n","61/61 [==============================] - ETA: 0s - loss: 3.3998 - accuracy: 0.0478\n","Epoch 19: val_accuracy did not improve from 0.05348\n","61/61 [==============================] - 34s 554ms/step - loss: 3.3998 - accuracy: 0.0478 - val_loss: 3.3993 - val_accuracy: 0.0481\n","Epoch 20/150\n","61/61 [==============================] - ETA: 0s - loss: 3.4012 - accuracy: 0.0478\n","Epoch 20: val_accuracy did not improve from 0.05348\n","61/61 [==============================] - 29s 475ms/step - loss: 3.4012 - accuracy: 0.0478 - val_loss: 3.3992 - val_accuracy: 0.0481\n","Epoch 21/150\n","61/61 [==============================] - ETA: 0s - loss: 3.3996 - accuracy: 0.0494\n","Epoch 21: val_accuracy did not improve from 0.05348\n","61/61 [==============================] - 30s 489ms/step - loss: 3.3996 - accuracy: 0.0494 - val_loss: 3.3991 - val_accuracy: 0.0481\n","Epoch 22/150\n","61/61 [==============================] - ETA: 0s - loss: 3.3998 - accuracy: 0.0478\n","Epoch 22: val_accuracy did not improve from 0.05348\n","61/61 [==============================] - 30s 494ms/step - loss: 3.3998 - accuracy: 0.0478 - val_loss: 3.3989 - val_accuracy: 0.0481\n","Epoch 23/150\n","61/61 [==============================] - ETA: 0s - loss: 3.4005 - accuracy: 0.0412\n","Epoch 23: val_accuracy did not improve from 0.05348\n","61/61 [==============================] - 28s 467ms/step - loss: 3.4005 - accuracy: 0.0412 - val_loss: 3.3988 - val_accuracy: 0.0481\n","Epoch 24/150\n","61/61 [==============================] - ETA: 0s - loss: 3.3996 - accuracy: 0.0494\n","Epoch 24: val_accuracy did not improve from 0.05348\n","61/61 [==============================] - 30s 487ms/step - loss: 3.3996 - accuracy: 0.0494 - val_loss: 3.3987 - val_accuracy: 0.0481\n","Epoch 25/150\n","61/61 [==============================] - ETA: 0s - loss: 3.3993 - accuracy: 0.0445\n","Epoch 25: val_accuracy did not improve from 0.05348\n","61/61 [==============================] - 31s 507ms/step - loss: 3.3993 - accuracy: 0.0445 - val_loss: 3.3986 - val_accuracy: 0.0481\n","Epoch 26/150\n","61/61 [==============================] - ETA: 0s - loss: 3.3994 - accuracy: 0.0478\n","Epoch 26: val_accuracy did not improve from 0.05348\n","61/61 [==============================] - 28s 463ms/step - loss: 3.3994 - accuracy: 0.0478 - val_loss: 3.3985 - val_accuracy: 0.0481\n","Epoch 27/150\n","61/61 [==============================] - ETA: 0s - loss: 3.4029 - accuracy: 0.0478\n","Epoch 27: val_accuracy did not improve from 0.05348\n","61/61 [==============================] - 29s 484ms/step - loss: 3.4029 - accuracy: 0.0478 - val_loss: 3.3983 - val_accuracy: 0.0481\n","Epoch 28/150\n","61/61 [==============================] - ETA: 0s - loss: 3.3990 - accuracy: 0.0478\n","Epoch 28: val_accuracy did not improve from 0.05348\n","61/61 [==============================] - 30s 491ms/step - loss: 3.3990 - accuracy: 0.0478 - val_loss: 3.3982 - val_accuracy: 0.0481\n","Epoch 29/150\n","61/61 [==============================] - ETA: 0s - loss: 3.4002 - accuracy: 0.0445\n","Epoch 29: val_accuracy did not improve from 0.05348\n","61/61 [==============================] - 28s 463ms/step - loss: 3.4002 - accuracy: 0.0445 - val_loss: 3.3981 - val_accuracy: 0.0481\n","Epoch 30/150\n","61/61 [==============================] - ETA: 0s - loss: 3.3986 - accuracy: 0.0494\n","Epoch 30: val_accuracy did not improve from 0.05348\n","61/61 [==============================] - 30s 492ms/step - loss: 3.3986 - accuracy: 0.0494 - val_loss: 3.3979 - val_accuracy: 0.0481\n","Epoch 31/150\n","61/61 [==============================] - ETA: 0s - loss: 3.3987 - accuracy: 0.0445\n","Epoch 31: val_accuracy did not improve from 0.05348\n","61/61 [==============================] - 31s 507ms/step - loss: 3.3987 - accuracy: 0.0445 - val_loss: 3.3978 - val_accuracy: 0.0481\n","Epoch 32/150\n","61/61 [==============================] - ETA: 0s - loss: 3.3985 - accuracy: 0.0478\n","Epoch 32: val_accuracy did not improve from 0.05348\n","61/61 [==============================] - 28s 466ms/step - loss: 3.3985 - accuracy: 0.0478 - val_loss: 3.3977 - val_accuracy: 0.0481\n","Epoch 33/150\n","61/61 [==============================] - ETA: 0s - loss: 3.3983 - accuracy: 0.0461\n","Epoch 33: val_accuracy did not improve from 0.05348\n","61/61 [==============================] - 30s 487ms/step - loss: 3.3983 - accuracy: 0.0461 - val_loss: 3.3976 - val_accuracy: 0.0481\n","Epoch 34/150\n","61/61 [==============================] - ETA: 0s - loss: 3.3984 - accuracy: 0.0494\n","Epoch 34: val_accuracy did not improve from 0.05348\n","61/61 [==============================] - 29s 484ms/step - loss: 3.3984 - accuracy: 0.0494 - val_loss: 3.3975 - val_accuracy: 0.0481\n","Epoch 35/150\n","61/61 [==============================] - ETA: 0s - loss: 3.3983 - accuracy: 0.0494\n","Epoch 35: val_accuracy did not improve from 0.05348\n","61/61 [==============================] - 28s 463ms/step - loss: 3.3983 - accuracy: 0.0494 - val_loss: 3.3973 - val_accuracy: 0.0481\n","Epoch 36/150\n","61/61 [==============================] - ETA: 0s - loss: 3.3979 - accuracy: 0.0461\n","Epoch 36: val_accuracy did not improve from 0.05348\n","61/61 [==============================] - 30s 486ms/step - loss: 3.3979 - accuracy: 0.0461 - val_loss: 3.3972 - val_accuracy: 0.0481\n","Epoch 37/150\n","61/61 [==============================] - ETA: 0s - loss: 3.3984 - accuracy: 0.0494\n","Epoch 37: val_accuracy did not improve from 0.05348\n","61/61 [==============================] - 31s 504ms/step - loss: 3.3984 - accuracy: 0.0494 - val_loss: 3.3971 - val_accuracy: 0.0481\n","Epoch 38/150\n","61/61 [==============================] - ETA: 0s - loss: 3.3978 - accuracy: 0.0478\n","Epoch 38: val_accuracy did not improve from 0.05348\n","61/61 [==============================] - 28s 464ms/step - loss: 3.3978 - accuracy: 0.0478 - val_loss: 3.3969 - val_accuracy: 0.0481\n","Epoch 39/150\n","61/61 [==============================] - ETA: 0s - loss: 3.3982 - accuracy: 0.0478\n","Epoch 39: val_accuracy did not improve from 0.05348\n","61/61 [==============================] - 29s 485ms/step - loss: 3.3982 - accuracy: 0.0478 - val_loss: 3.3968 - val_accuracy: 0.0481\n","Epoch 40/150\n","61/61 [==============================] - ETA: 0s - loss: 3.3978 - accuracy: 0.0478\n","Epoch 40: val_accuracy did not improve from 0.05348\n","61/61 [==============================] - 30s 486ms/step - loss: 3.3978 - accuracy: 0.0478 - val_loss: 3.3967 - val_accuracy: 0.0481\n","Epoch 41/150\n","61/61 [==============================] - ETA: 0s - loss: 3.3978 - accuracy: 0.0494\n","Epoch 41: val_accuracy did not improve from 0.05348\n","61/61 [==============================] - 30s 488ms/step - loss: 3.3978 - accuracy: 0.0494 - val_loss: 3.3965 - val_accuracy: 0.0481\n","Epoch 42/150\n","61/61 [==============================] - ETA: 0s - loss: 3.3971 - accuracy: 0.0478\n","Epoch 42: val_accuracy did not improve from 0.05348\n","61/61 [==============================] - 28s 466ms/step - loss: 3.3971 - accuracy: 0.0478 - val_loss: 3.3964 - val_accuracy: 0.0481\n","Epoch 43/150\n","61/61 [==============================] - ETA: 0s - loss: 3.3976 - accuracy: 0.0478\n","Epoch 43: val_accuracy did not improve from 0.05348\n","61/61 [==============================] - 31s 506ms/step - loss: 3.3976 - accuracy: 0.0478 - val_loss: 3.3963 - val_accuracy: 0.0481\n","Epoch 44/150\n","61/61 [==============================] - ETA: 0s - loss: 3.3973 - accuracy: 0.0527\n","Epoch 44: val_accuracy did not improve from 0.05348\n","61/61 [==============================] - 30s 484ms/step - loss: 3.3973 - accuracy: 0.0527 - val_loss: 3.3961 - val_accuracy: 0.0481\n","Epoch 45/150\n","61/61 [==============================] - ETA: 0s - loss: 3.3970 - accuracy: 0.0461\n","Epoch 45: val_accuracy did not improve from 0.05348\n","61/61 [==============================] - 28s 464ms/step - loss: 3.3970 - accuracy: 0.0461 - val_loss: 3.3960 - val_accuracy: 0.0481\n","Epoch 46/150\n","61/61 [==============================] - ETA: 0s - loss: 3.3985 - accuracy: 0.0494\n","Epoch 46: val_accuracy did not improve from 0.05348\n","61/61 [==============================] - 30s 491ms/step - loss: 3.3985 - accuracy: 0.0494 - val_loss: 3.3959 - val_accuracy: 0.0481\n","Epoch 47/150\n","61/61 [==============================] - ETA: 0s - loss: 3.3978 - accuracy: 0.0478\n","Epoch 47: val_accuracy did not improve from 0.05348\n","61/61 [==============================] - 30s 490ms/step - loss: 3.3978 - accuracy: 0.0478 - val_loss: 3.3958 - val_accuracy: 0.0481\n","Epoch 48/150\n","61/61 [==============================] - ETA: 0s - loss: 3.3966 - accuracy: 0.0478\n","Epoch 48: val_accuracy did not improve from 0.05348\n","61/61 [==============================] - 32s 524ms/step - loss: 3.3966 - accuracy: 0.0478 - val_loss: 3.3957 - val_accuracy: 0.0481\n","Epoch 49/150\n","61/61 [==============================] - ETA: 0s - loss: 3.3965 - accuracy: 0.0461\n","Epoch 49: val_accuracy did not improve from 0.05348\n","61/61 [==============================] - 28s 463ms/step - loss: 3.3965 - accuracy: 0.0461 - val_loss: 3.3956 - val_accuracy: 0.0481\n","Epoch 50/150\n","61/61 [==============================] - ETA: 0s - loss: 3.3983 - accuracy: 0.0478\n","Epoch 50: val_accuracy did not improve from 0.05348\n","61/61 [==============================] - 30s 487ms/step - loss: 3.3983 - accuracy: 0.0478 - val_loss: 3.3955 - val_accuracy: 0.0481\n","Epoch 51/150\n","61/61 [==============================] - ETA: 0s - loss: 3.3971 - accuracy: 0.0478\n","Epoch 51: val_accuracy did not improve from 0.05348\n","61/61 [==============================] - 28s 468ms/step - loss: 3.3971 - accuracy: 0.0478 - val_loss: 3.3953 - val_accuracy: 0.0481\n","Epoch 52/150\n","61/61 [==============================] - ETA: 0s - loss: 3.3970 - accuracy: 0.0478\n","Epoch 52: val_accuracy did not improve from 0.05348\n","61/61 [==============================] - 30s 485ms/step - loss: 3.3970 - accuracy: 0.0478 - val_loss: 3.3952 - val_accuracy: 0.0481\n","Epoch 53/150\n","61/61 [==============================] - ETA: 0s - loss: 3.3952 - accuracy: 0.0494\n","Epoch 53: val_accuracy did not improve from 0.05348\n","61/61 [==============================] - 29s 479ms/step - loss: 3.3952 - accuracy: 0.0494 - val_loss: 3.3950 - val_accuracy: 0.0481\n","Epoch 54/150\n","61/61 [==============================] - ETA: 0s - loss: 3.3966 - accuracy: 0.0461\n","Epoch 54: val_accuracy did not improve from 0.05348\n","61/61 [==============================] - 29s 483ms/step - loss: 3.3966 - accuracy: 0.0461 - val_loss: 3.3949 - val_accuracy: 0.0481\n","Epoch 55/150\n","61/61 [==============================] - ETA: 0s - loss: 3.3961 - accuracy: 0.0478\n","Epoch 55: val_accuracy did not improve from 0.05348\n","61/61 [==============================] - 28s 464ms/step - loss: 3.3961 - accuracy: 0.0478 - val_loss: 3.3948 - val_accuracy: 0.0481\n","Epoch 56/150\n","61/61 [==============================] - ETA: 0s - loss: 3.3961 - accuracy: 0.0478\n","Epoch 56: val_accuracy did not improve from 0.05348\n","61/61 [==============================] - 30s 486ms/step - loss: 3.3961 - accuracy: 0.0478 - val_loss: 3.3947 - val_accuracy: 0.0481\n","Epoch 57/150\n","61/61 [==============================] - ETA: 0s - loss: 3.3958 - accuracy: 0.0478\n","Epoch 57: val_accuracy did not improve from 0.05348\n","61/61 [==============================] - 30s 486ms/step - loss: 3.3958 - accuracy: 0.0478 - val_loss: 3.3946 - val_accuracy: 0.0481\n","Epoch 58/150\n","61/61 [==============================] - ETA: 0s - loss: 3.3963 - accuracy: 0.0478\n","Epoch 58: val_accuracy did not improve from 0.05348\n","61/61 [==============================] - 30s 492ms/step - loss: 3.3963 - accuracy: 0.0478 - val_loss: 3.3944 - val_accuracy: 0.0481\n","Epoch 59/150\n","61/61 [==============================] - ETA: 0s - loss: 3.3957 - accuracy: 0.0478\n","Epoch 59: val_accuracy did not improve from 0.05348\n","61/61 [==============================] - 29s 474ms/step - loss: 3.3957 - accuracy: 0.0478 - val_loss: 3.3943 - val_accuracy: 0.0481\n","Epoch 60/150\n","61/61 [==============================] - ETA: 0s - loss: 3.3960 - accuracy: 0.0478\n","Epoch 60: val_accuracy did not improve from 0.05348\n","61/61 [==============================] - 31s 510ms/step - loss: 3.3960 - accuracy: 0.0478 - val_loss: 3.3942 - val_accuracy: 0.0481\n","Epoch 61/150\n","61/61 [==============================] - ETA: 0s - loss: 3.3961 - accuracy: 0.0478\n","Epoch 61: val_accuracy did not improve from 0.05348\n","61/61 [==============================] - 30s 489ms/step - loss: 3.3961 - accuracy: 0.0478 - val_loss: 3.3941 - val_accuracy: 0.0481\n","Epoch 62/150\n","61/61 [==============================] - ETA: 0s - loss: 3.3956 - accuracy: 0.0478\n","Epoch 62: val_accuracy did not improve from 0.05348\n","61/61 [==============================] - 28s 464ms/step - loss: 3.3956 - accuracy: 0.0478 - val_loss: 3.3940 - val_accuracy: 0.0481\n","Epoch 63/150\n","61/61 [==============================] - ETA: 0s - loss: 3.3956 - accuracy: 0.0478\n","Epoch 63: val_accuracy did not improve from 0.05348\n","61/61 [==============================] - 29s 482ms/step - loss: 3.3956 - accuracy: 0.0478 - val_loss: 3.3939 - val_accuracy: 0.0481\n","Epoch 64/150\n","61/61 [==============================] - ETA: 0s - loss: 3.3949 - accuracy: 0.0461\n","Epoch 64: val_accuracy did not improve from 0.05348\n","61/61 [==============================] - 29s 484ms/step - loss: 3.3949 - accuracy: 0.0461 - val_loss: 3.3937 - val_accuracy: 0.0481\n","Epoch 65/150\n","61/61 [==============================] - ETA: 0s - loss: 3.3965 - accuracy: 0.0478\n","Epoch 65: val_accuracy did not improve from 0.05348\n","61/61 [==============================] - 28s 462ms/step - loss: 3.3965 - accuracy: 0.0478 - val_loss: 3.3937 - val_accuracy: 0.0481\n","Epoch 66/150\n","61/61 [==============================] - ETA: 0s - loss: 3.3954 - accuracy: 0.0478\n","Epoch 66: val_accuracy did not improve from 0.05348\n","61/61 [==============================] - 31s 505ms/step - loss: 3.3954 - accuracy: 0.0478 - val_loss: 3.3935 - val_accuracy: 0.0481\n","Epoch 67/150\n","61/61 [==============================] - ETA: 0s - loss: 3.3952 - accuracy: 0.0478\n","Epoch 67: val_accuracy did not improve from 0.05348\n","61/61 [==============================] - 29s 483ms/step - loss: 3.3952 - accuracy: 0.0478 - val_loss: 3.3934 - val_accuracy: 0.0481\n","Epoch 68/150\n","61/61 [==============================] - ETA: 0s - loss: 3.3954 - accuracy: 0.0478\n","Epoch 68: val_accuracy did not improve from 0.05348\n","61/61 [==============================] - 29s 470ms/step - loss: 3.3954 - accuracy: 0.0478 - val_loss: 3.3933 - val_accuracy: 0.0481\n","Epoch 69/150\n","61/61 [==============================] - ETA: 0s - loss: 3.3955 - accuracy: 0.0478\n","Epoch 69: val_accuracy did not improve from 0.05348\n","61/61 [==============================] - 29s 474ms/step - loss: 3.3955 - accuracy: 0.0478 - val_loss: 3.3932 - val_accuracy: 0.0481\n","Epoch 70/150\n","61/61 [==============================] - ETA: 0s - loss: 3.3947 - accuracy: 0.0478\n","Epoch 70: val_accuracy did not improve from 0.05348\n","61/61 [==============================] - 29s 478ms/step - loss: 3.3947 - accuracy: 0.0478 - val_loss: 3.3931 - val_accuracy: 0.0481\n","Epoch 71/150\n","61/61 [==============================] - ETA: 0s - loss: 3.3948 - accuracy: 0.0478\n","Epoch 71: val_accuracy did not improve from 0.05348\n","61/61 [==============================] - 28s 464ms/step - loss: 3.3948 - accuracy: 0.0478 - val_loss: 3.3930 - val_accuracy: 0.0481\n","Epoch 72/150\n","61/61 [==============================] - ETA: 0s - loss: 3.3951 - accuracy: 0.0478\n","Epoch 72: val_accuracy did not improve from 0.05348\n","61/61 [==============================] - 28s 461ms/step - loss: 3.3951 - accuracy: 0.0478 - val_loss: 3.3929 - val_accuracy: 0.0481\n","Epoch 73/150\n","10/61 [===>..........................] - ETA: 19s - loss: 3.3977 - accuracy: 0.0412"]}],"source":["# set up logging \n","# and train nerual net\n","\n","%load_ext tensorboard\n","\n","log_dir = 'logs/batch/' + datetime.now().strftime('%Y%m%d-%H%M%S') + '/train'\n","tensorboard_callback = keras.callbacks.TensorBoard(log_dir = log_dir)\n","checkpoint_callback = keras.callbacks.ModelCheckpoint(\n","    filepath = checkpoint_path, monitor=\"val_accuracy\", batch_size = img_batch_size_,\n","    verbose=1, mode=\"max\", save_weights_only=True, save_best_only=True)\n","history = model.fit(trainD_shuffle, epochs = epochs_, validation_data = testD_noshuffle, \n","    callbacks=[tensorboard_callback, checkpoint_callback])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o2MMcZbTwfZ_"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5Ifchf1pvj2Q"},"outputs":[],"source":["# CHANGE:  Plot training and validation accuracy over epochs\n","import matplotlib.pyplot as plt\n","accuracy = history.history[\"accuracy\"]\n","val_accuracy = history.history[\"val_accuracy\"]\n","loss = history.history[\"loss\"]\n","val_loss = history.history[\"val_loss\"]\n","epochs = range(1, len(accuracy) + 1)\n","plt.plot(epochs, accuracy, \"bo\", label = \"Training accuracy\")\n","plt.plot(epochs, val_accuracy, \"g\", label = \"Validation accuracy\")\n","plt.title(\"Training and validation accuracy\")\n","plt.legend()\n","plt.figure()\n","plt.plot(epochs, loss, \"bo\", label = \"Training loss\")\n","plt.plot(epochs, val_loss, \"g\", label = \"Validation loss\")\n","plt.yscale(\"log\")\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JLNMPQ9xnM87"},"outputs":[],"source":["# restore checkpoint model\n","#model = keras.models.load_model(checkpoint_path)\n","model.load_weights(checkpoint_path)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yKS2eweInPxr"},"outputs":[],"source":["# run prediction based on training data\n","train_scores = model.predict(trainD_noshuffle)\n","train_pred_labels = train_scores.argmax(axis = 1)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QOXJzKEvnSbA"},"outputs":[],"source":["# evaluate trained network\n","print('')\n","print('')\n","print('Model Evaluation Using Training Data:')\n","\n","print(\"Accuracy Score\")\n","print(accuracy_score(trainD_noshuffle.labels, train_pred_labels))\n","\n","print(\"Confusion Matrix\")\n","print(confusion_matrix(trainD_noshuffle.labels, train_pred_labels))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pwOAsHg_nVqE"},"outputs":[],"source":["# run prediction based on test data\n","test_scores = model.predict(testD_noshuffle)\n","test_pred_labels = test_scores.argmax(axis = 1)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oRRlkRM2nXX-"},"outputs":[],"source":["# print confusion matrix \n","print('')\n","print('')\n","print('Model Evaluation Using Test Data:')\n","\n","\n","print(\"Accuracy Score\")\n","print(accuracy_score(testD_noshuffle.labels, test_pred_labels))\n","\n","print(\"Confusion Matrix\")\n","print(confusion_matrix(testD_noshuffle.labels, test_pred_labels))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mKDbOBkhnZfa"},"outputs":[],"source":["# Create lookup to convert class labels (index-numbers) to string labels \n","nameToLabelDict = testD_noshuffle.class_indices\n","labelToNameDict = dict([(value, key) for key, value in nameToLabelDict.items()])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"I_Y4eDRunjMW"},"outputs":[],"source":["# set up lists of colors and styles for use in plotting\n","from itertools import cycle\n","from itertools import product\n","from sklearn.linear_model import LassoCV\n","import matplotlib as mpl\n","color_list = [\\\n","    \"b\", \"r\", \"g\", \"c\", \"m\", \\\n","    \"skyblue\", \"pink\", \"lime\", \"cyan\", \"magenta\", \\\n","    \"navy\", \"brown\", \"olive\", \"orange\", \"purple\"]\n","    # note \"cyan\" is brighter than \"c\", \"magenta\" is brighter than \"m\"\n","\n","# repeat each style times number of colors\n","base_style_list = ['solid', 'dotted', 'dashed', 'dashdot']\n","line_style_list = \\\n","    [cartesian[0] for  cartesian in product(base_style_list, color_list)]\n","\n","# set up plot styling\n","mpl.style.use('seaborn')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"H-6OUDNtnlz1"},"outputs":[],"source":["# Plot ROC (Receiver Operating Characteristic) Curve and compute area under curve for each class \n","# using test data\n","import matplotlib as mpl\n","import seaborn as sms\n","mpl.style.use('seaborn')\n","import matplotlib.pyplot as plt\n","# Compute ROC curve and ROC area for each class\n","from sklearn.metrics import roc_curve, auc\n","fig, ax = plt.subplots()\n","for i, c, l in zip(range(img_class_count), cycle(color_list), line_style_list):\n","    fpr_, tpr_, _ = roc_curve(testD_noshuffle.labels, test_scores[:, i], pos_label=i)\n","    auc_ = auc(fpr_, tpr_)\n","    label_ = 'class ' + str(i) + \" (\" + labelToNameDict[i] + \") AUC = %0.2f)\" % auc_\n","    plt.plot(fpr_, tpr_, marker='.', label=label_, color = c, linestyle = l)\n","plt.title(\"Test Data ROC Curve\", color='C6')\n","plt.xlabel('False Positive Rate')\n","plt.ylabel('True Positive Rate')\n","ax.legend(bbox_to_anchor = (1.0,1.0), loc = \"upper left\", fontsize = \"x-small\")\n","#plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nPxA897BnoOB"},"outputs":[],"source":["# Print precision, recall, F-score for each class \n","# using test data\n","from sklearn.metrics import classification_report\n","scores = classification_report(testD_noshuffle.labels, test_pred_labels)\n","print(scores)"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"authorship_tag":"ABX9TyNRNZG0aY+x5zL61N6s7DW/"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}