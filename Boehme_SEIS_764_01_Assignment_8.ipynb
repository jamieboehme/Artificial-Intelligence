{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## SEIS 764-01 Assignment 8\n",
        "**Jamie Boehme**"
      ],
      "metadata": {
        "id": "jaPN-cQzBF3i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import libraries for processing"
      ],
      "metadata": {
        "id": "bqW3qiGJBHKX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Dense, Activation, Dropout, Flatten, MaxPooling2D, BatchNormalization\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import utils\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, accuracy_score\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "i_NxcYkkBGxo"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read data from google colab drive"
      ],
      "metadata": {
        "id": "PlCqaTt2BPqu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "data_path = \"/content/drive/My Drive/Colab Notebooks/CNN_Flowers\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "MhxMyDsQDdFi",
        "outputId": "fabbf507-f1d8-425d-c98f-2c4cade95701"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 10\n",
        "\n",
        "data = ImageDataGenerator(rescale=1. / 255, \n",
        "                          validation_split=0.2)\n",
        "\n",
        "training_data1 = data.flow_from_directory('/content/drive/My Drive/Colab Notebooks/CNN_Flowers', \n",
        "                                         target_size=(200, 200), shuffle=True, batch_size = batch_size, \n",
        "                                         class_mode='categorical', subset='training')\n",
        "\n",
        "training_data_noshuffle1 = data.flow_from_directory('/content/drive/My Drive/Colab Notebooks/CNN_Flowers', \n",
        "                                         target_size=(200, 200), shuffle=False, batch_size = batch_size, \n",
        "                                         class_mode='categorical', subset='training')\n",
        "\n",
        "test_data1 = data.flow_from_directory('/content/drive/My Drive/Colab Notebooks/CNN_Flowers', \n",
        "                                     target_size=(200, 200), batch_size = batch_size, shuffle=False,\n",
        "                                     class_mode='categorical', subset='validation')\n",
        "\n",
        "training_data2 = data.flow_from_directory('/content/drive/My Drive/Colab Notebooks/CNN_Flowers', \n",
        "                                         target_size=(200, 200), shuffle=True, batch_size = batch_size, \n",
        "                                         class_mode='categorical', subset='training')\n",
        "\n",
        "training_data_noshuffle2 = data.flow_from_directory('/content/drive/My Drive/Colab Notebooks/CNN_Flowers', \n",
        "                                         target_size=(200, 200), shuffle=False, batch_size = batch_size, \n",
        "                                         class_mode='categorical', subset='training')\n",
        "\n",
        "test_data2 = data.flow_from_directory('/content/drive/My Drive/Colab Notebooks/CNN_Flowers', \n",
        "                                     target_size=(200, 200), batch_size = batch_size, shuffle=False,\n",
        "                                     class_mode='categorical', subset='validation')\n",
        "\n",
        "numClasses = 2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Qe0jUCxhBJWn",
        "outputId": "c8c395d9-5201-4d51-f851-4f0c8ca5d2b8"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 90 images belonging to 2 classes.\n",
            "Found 90 images belonging to 2 classes.\n",
            "Found 22 images belonging to 2 classes.\n",
            "Found 90 images belonging to 2 classes.\n",
            "Found 90 images belonging to 2 classes.\n",
            "Found 22 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train initial pre-built model"
      ],
      "metadata": {
        "id": "3tqgcnrqH1TH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Classifier1=Sequential()\n",
        "Classifier1.add(Conv2D(64, kernel_size=(5, 5), input_shape=(200, 200, 3)))\n",
        "Classifier1.add(BatchNormalization())\n",
        "Classifier1.add(Activation('relu'))\n",
        "Classifier1.add(MaxPooling2D(pool_size=(2,2)))\n",
        "Classifier1.add(Dropout(0.2))\n",
        "               \n",
        "Classifier1.add(Conv2D(32, kernel_size=(3, 3)))\n",
        "Classifier1.add(BatchNormalization())\n",
        "Classifier1.add(Activation('relu'))\n",
        "Classifier1.add(MaxPooling2D(pool_size=(2,2)))\n",
        "Classifier1.add(Dropout(0.2))\n",
        "\n",
        "Classifier1.add(Flatten())\n",
        "\n",
        "Classifier1.add(Dense(64, activation='relu'))\n",
        "Classifier1.add(Dense(32, activation='relu'))\n",
        "Classifier1.add(Dense(16, activation='relu'))\n",
        "Classifier1.add(Dense(8, activation='relu'))\n",
        "Classifier1.add(Dense(numClasses, activation='softmax'))"
      ],
      "metadata": {
        "id": "EBn2IVeCGOqw"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MyEpochs = 30\n",
        "opt = keras.optimizers.Adam(learning_rate=0.01)\n",
        "#opt = keras.optimizers.SGD(learning_rate=0.001, momentum=0.9)\n",
        "\n",
        "Classifier1.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=opt, \n",
        "              metrics=['accuracy']) \n",
        "\n",
        "Classifier1.fit(training_data1,\n",
        "                        batch_size = 10,\n",
        "                        epochs = MyEpochs,\n",
        "                        validation_data=test_data1,\n",
        "                        shuffle = 1,\n",
        "                        verbose =0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "gFDp_h0xGYva",
        "outputId": "bd6dbfbb-1a0f-4ee6-d034-ba7bf59d09e8"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f50b366ca50>"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_data1.reset()\n",
        "test_data1.reset()\n",
        "\n",
        "predicted_scores1 = Classifier1.predict(test_data1, verbose=1)\n",
        "predicted_labels1 = predicted_scores1.argmax(axis=1) \n",
        "\n",
        "test_labels1 = test_data1.labels\n",
        "\n",
        "acc_score_pre = accuracy_score(test_labels1, predicted_labels1)\n",
        "CFM1 = confusion_matrix(test_labels1, predicted_labels1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "iH7DhrtuHD_q",
        "outputId": "b5043731-8641-4bb3-9426-326e008c3934"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 1s 191ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train a second model, that produces better results"
      ],
      "metadata": {
        "id": "nMnhpzm7Ln-X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Classifier2=Sequential()\n",
        "Classifier2.add(Conv2D(16, kernel_size=(5, 5), input_shape=(200, 200, 3)))\n",
        "Classifier2.add(BatchNormalization())\n",
        "Classifier2.add(Activation('relu'))\n",
        "               \n",
        "Classifier2=Sequential()\n",
        "Classifier2.add(Conv2D(32, kernel_size=(3, 3)))\n",
        "Classifier2.add(BatchNormalization())\n",
        "Classifier2.add(Activation('relu'))\n",
        "Classifier2.add(Dropout(0.1))\n",
        "\n",
        "Classifier2.add(Conv2D(64, kernel_size=(3, 3)))\n",
        "Classifier2.add(BatchNormalization())\n",
        "Classifier2.add(Activation('relu'))\n",
        "Classifier2.add(MaxPooling2D(pool_size=(2,2)))\n",
        "Classifier2.add(Dropout(0.1))\n",
        "\n",
        "Classifier2.add(Flatten())\n",
        "\n",
        "Classifier2.add(Dense(64, activation='relu'))\n",
        "Classifier2.add(Dense(40, activation='relu'))\n",
        "Classifier2.add(Dense(32, activation='relu'))\n",
        "Classifier2.add(Dense(16, activation='relu'))\n",
        "Classifier2.add(Dense(8, activation='relu'))\n",
        "Classifier2.add(Dense(numClasses, activation='softmax'))"
      ],
      "metadata": {
        "id": "Tiz_ylGaBmQA"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MyEpochs = 40\n",
        "opt = SGD(learning_rate=0.01)\n",
        "\n",
        "Classifier2.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=opt, \n",
        "              metrics=['accuracy']) \n",
        "\n",
        "Classifier2.fit(training_data2,\n",
        "                        batch_size = 6,\n",
        "                        epochs = MyEpochs,\n",
        "                        validation_data=test_data2,\n",
        "                        shuffle = 1,\n",
        "                        verbose=1)"
      ],
      "metadata": {
        "id": "yVwlZJlCGFGj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Print the configurations (i.e. architecture) of all the layers in your CNN"
      ],
      "metadata": {
        "id": "X05ryQx1MEC5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Classifier2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "XE2FMbroGoz_",
        "outputId": "cd97fc8a-71f6-436e-fa4e-cd361aae97f0"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_20\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_51 (Conv2D)          (None, None, None, 32)    896       \n",
            "                                                                 \n",
            " batch_normalization_48 (Bat  (None, None, None, 32)   128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_50 (Activation)  (None, None, None, 32)    0         \n",
            "                                                                 \n",
            " dropout_42 (Dropout)        (None, None, None, 32)    0         \n",
            "                                                                 \n",
            " conv2d_52 (Conv2D)          (None, None, None, 64)    18496     \n",
            "                                                                 \n",
            " batch_normalization_49 (Bat  (None, None, None, 64)   256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_51 (Activation)  (None, None, None, 64)    0         \n",
            "                                                                 \n",
            " max_pooling2d_32 (MaxPoolin  (None, None, None, 64)   0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_43 (Dropout)        (None, None, None, 64)    0         \n",
            "                                                                 \n",
            " flatten_18 (Flatten)        (None, None)              0         \n",
            "                                                                 \n",
            " dense_90 (Dense)            (None, 64)                39338048  \n",
            "                                                                 \n",
            " dense_91 (Dense)            (None, 40)                2600      \n",
            "                                                                 \n",
            " dense_92 (Dense)            (None, 32)                1312      \n",
            "                                                                 \n",
            " dense_93 (Dense)            (None, 16)                528       \n",
            "                                                                 \n",
            " dense_94 (Dense)            (None, 8)                 136       \n",
            "                                                                 \n",
            " dense_95 (Dense)            (None, 2)                 18        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 39,362,418\n",
            "Trainable params: 39,362,226\n",
            "Non-trainable params: 192\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. What are the testing accuracies before and after you modify the program?"
      ],
      "metadata": {
        "id": "x1upj-9XMOMw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_data2.reset()\n",
        "test_data2.reset()\n",
        "\n",
        "predicted_scores2 = Classifier2.predict(test_data2, verbose=1)\n",
        "predicted_labels2 = predicted_scores2.argmax(axis=1) \n",
        "\n",
        "test_labels2 = test_data2.labels\n",
        "\n",
        "acc_score_post = accuracy_score(test_labels2, predicted_labels2)\n",
        "CFM2 = confusion_matrix(test_labels2, predicted_labels2)\n",
        "\n",
        "\n",
        "print(\"\\n\", \"Accuracy of Pre-Trained Model: \" + str(format(acc_score_pre,'.3f')))\n",
        "print(\"\\n\", \"Accuracy of 2nd, Better Model: \" + str(format(acc_score_post,'.3f')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "MiEKM2kiJBH0",
        "outputId": "785333b5-8778-4c4a-a66e-bb3d27c18b0d"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 1s 317ms/step\n",
            "\n",
            " Accuracy of Pre-Trained Model: 0.864\n",
            "\n",
            " Accuracy of 2nd, Better Model: 0.955\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Print the confusion matrix of your classification result before and after you\n",
        "modify the program. "
      ],
      "metadata": {
        "id": "i3bJZQneI2I2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\", \"Pre-trained Confusion Matrix: \\n\", CFM1)\n",
        "print(\"\\n\", \"2nd, Better Model Confusion Matrix: \\n\", CFM2)\n",
        "\n",
        "print(\"\\n\", \"Pre-trained classification report: \\n\", classification_report(test_labels1, predicted_labels1))\n",
        "print(\"\\n\", \"2nd, Better Model classification report: \\n\", classification_report(test_labels2, predicted_labels2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "tSC2HEA0I4AX",
        "outputId": "19cab3cf-d6e0-463f-dca0-f44ea036ff15"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Pre-trained Confusion Matrix: \n",
            " [[ 9  2]\n",
            " [ 1 10]]\n",
            "\n",
            " 2nd, Better Model Confusion Matrix: \n",
            " [[10  1]\n",
            " [ 0 11]]\n",
            "\n",
            " Pre-trained classification report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.82      0.86        11\n",
            "           1       0.83      0.91      0.87        11\n",
            "\n",
            "    accuracy                           0.86        22\n",
            "   macro avg       0.87      0.86      0.86        22\n",
            "weighted avg       0.87      0.86      0.86        22\n",
            "\n",
            "\n",
            " 2nd, Better Model classification report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.91      0.95        11\n",
            "           1       0.92      1.00      0.96        11\n",
            "\n",
            "    accuracy                           0.95        22\n",
            "   macro avg       0.96      0.95      0.95        22\n",
            "weighted avg       0.96      0.95      0.95        22\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. What changes did you make to the program for the differences you saw in\n",
        "question 1? I made the following changes to the initial program:\n",
        "- Started my program with less filters on the original images, and grew the level of filters rather than decreasing the original filters. I did this, so that the model conforms to best practices for AI, increasing filters and deacreasing the size of the image over time to abstract local features.\n",
        "- Grew my filters more slowly than the original model decreased filters, to allow the program to gradually learn over time - and decreased my fully connected layers more slowly.\n",
        "- Reduced drop-out, knowing there were already limited images to see if I could still receive good testing results\n",
        "- Decreased the batch size in order to increase backpropogation, and therefore faster learning of the images over each epoch\n",
        "- Had additional fully connected layers to slow drop-off at each fully connected layer\n",
        "- Increased the number of epochs, as it appeared the learning had not yet stalled at 30 epochs\n",
        "\n",
        "Things to note: This model seems very fragile. It seems that the accuracy and precision can vary widely based upon each runtime."
      ],
      "metadata": {
        "id": "tY-kYbxQKHSz"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xuqHcjZCrn3a"
      },
      "execution_count": 70,
      "outputs": []
    }
  ]
}