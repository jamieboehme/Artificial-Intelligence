{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## SEIS 764-01 Assignment 9\n",
        "**Jamie Boehme**"
      ],
      "metadata": {
        "id": "jaPN-cQzBF3i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import libraries for processing"
      ],
      "metadata": {
        "id": "bqW3qiGJBHKX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Dense, Activation, Dropout, Flatten, MaxPooling2D, BatchNormalization\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import utils\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, accuracy_score, roc_curve, auc\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "i_NxcYkkBGxo"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read data from google colab drive"
      ],
      "metadata": {
        "id": "PlCqaTt2BPqu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "data_path = \"/content/drive/My Drive/Colab Notebooks/CNN_Flowers\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "MhxMyDsQDdFi",
        "outputId": "c10468a8-17f2-4a7f-a1d6-141861bace12"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 10\n",
        "\n",
        "data = ImageDataGenerator(rescale=1. / 255, \n",
        "                          validation_split=0.2)\n",
        "\n",
        "training_data = data.flow_from_directory('/content/drive/My Drive/Colab Notebooks/Iris_Imgs', \n",
        "                                         target_size=(224, 224), shuffle=True, batch_size = batch_size, \n",
        "                                         class_mode='categorical', subset='training')\n",
        "\n",
        "training_data_noshuffle = data.flow_from_directory('/content/drive/My Drive/Colab Notebooks/Iris_Imgs', \n",
        "                                         target_size=(224, 224), shuffle=False, batch_size = batch_size, \n",
        "                                         class_mode='categorical', subset='training')\n",
        "\n",
        "test_data = data.flow_from_directory('/content/drive/My Drive/Colab Notebooks/Iris_Imgs', \n",
        "                                     target_size=(224, 224), batch_size = batch_size, shuffle=False,\n",
        "                                     class_mode='categorical', subset='validation')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Qe0jUCxhBJWn",
        "outputId": "23680088-0ca2-4645-a0fe-f3a6f3ea9777"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 120 images belonging to 3 classes.\n",
            "Found 120 images belonging to 3 classes.\n",
            "Found 30 images belonging to 3 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train initial pre-built model"
      ],
      "metadata": {
        "id": "3tqgcnrqH1TH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_xfer = tf.keras.applications.VGG16(\n",
        "    include_top = False,\n",
        "    weights = \"imagenet\",\n",
        "    input_shape = (224,224,3)\n",
        ")\n",
        "\n",
        "cnn_xfer.trainable=False #freezing weights"
      ],
      "metadata": {
        "id": "EBn2IVeCGOqw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "e6701d01-804b-4967-86ff-61f16867053a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Print the configurations of all the layers in the CNN"
      ],
      "metadata": {
        "id": "GauZlDoAyAgy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_xfer.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "8rDHQcF9k2nB",
        "outputId": "5e24e4ea-72c1-4819-a0c8-e6e205501de1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 0\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Write a program using Python Keras, MatLab, or any programming language of \n",
        "your choice to classify images into 3 classes (setosa, versicolor, virginica) using any pre-trained CNN listed on slide 7 to 9 "
      ],
      "metadata": {
        "id": "sMTUrAMJyNCv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "flatten_layer = tf.keras.layers.Flatten()\n",
        "dense_layer_1 = Dense(500, activation='relu')\n",
        "dense_layer_2 = Dense(250, activation='relu')\n",
        "dense_layer_3 = Dense(50, activation='relu')\n",
        "prediction_layer = Dense(3, activation='softmax')\n",
        "\n",
        "\n",
        "model = Sequential([\n",
        "    cnn_xfer,\n",
        "    flatten_layer,\n",
        "    dense_layer_1,\n",
        "    dense_layer_2,\n",
        "    dense_layer_3,\n",
        "    prediction_layer\n",
        "])"
      ],
      "metadata": {
        "id": "_FE-wcPflAAX"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "4lAiK2aqlRMA",
        "outputId": "6aa2f52e-1584-4f3f-b9e1-854c0b3d5f39"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " vgg16 (Functional)          (None, 7, 7, 512)         14714688  \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 25088)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 500)               12544500  \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 250)               125250    \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 50)                12550     \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 3)                 153       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 27,397,141\n",
            "Trainable params: 12,682,453\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#opt = tf.keras.optimizers.SGD(learning_rate=0.01)\n",
        "model.compile(loss=tf.keras.losses.categorical_crossentropy, metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "SR-57yzllVyl"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(training_data, batch_size = 10, epochs = 30, validation_data=test_data, shuffle = 1, verbose = 1)"
      ],
      "metadata": {
        "id": "Et35RD2ImL_j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Print the confusion matrix of your classification result, and what is the accuracy of classification result? Below are the results of the **test** data"
      ],
      "metadata": {
        "id": "OATSGBWBw3Wo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_data.reset()\n",
        "test_data.reset()\n",
        "\n",
        "predicted_scores = model.predict(test_data, verbose=1)\n",
        "predicted_labels = predicted_scores.argmax(axis=1) \n",
        "\n",
        "test_labels = test_data.labels\n",
        "\n",
        "acc_score_xfer_cnn = accuracy_score(test_labels, predicted_labels)\n",
        "xfer_cnn_cfm = confusion_matrix(test_labels, predicted_labels)\n",
        "\n",
        "print(\"Accuracy score: \", acc_score_xfer_cnn)\n",
        "print(\"Confusion Matrix: \\n\", xfer_cnn_cfm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "iH7DhrtuHD_q",
        "outputId": "a34a2317-da18-459e-f4a4-65ec29e3bc33"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 16s 5s/step\n",
            "Accuracy score:  0.9333333333333333\n",
            "Confusion Matrix: \n",
            " [[ 8  2  0]\n",
            " [ 0 10  0]\n",
            " [ 0  0 10]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Print the precision, recall, F-score for EACH class. Also, create a ROC curve and measure its AUC for EACH class."
      ],
      "metadata": {
        "id": "1UwCign8xCaS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Classification Matrix: \\n\", classification_report(test_labels, predicted_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "JqJpgxPj4aFJ",
        "outputId": "c30e6bc0-bcd1-4ba4-baa2-77e0fc6a839f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Matrix: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.80      0.89        10\n",
            "           1       0.83      1.00      0.91        10\n",
            "           2       1.00      1.00      1.00        10\n",
            "\n",
            "    accuracy                           0.93        30\n",
            "   macro avg       0.94      0.93      0.93        30\n",
            "weighted avg       0.94      0.93      0.93        30\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_keras = predicted_scores\n",
        "from sklearn.preprocessing import label_binarize\n",
        "y_test = label_binarize(test_data.labels, classes=[0,1,2])\n",
        "n_classes = 3\n",
        "\n",
        "fpr = dict()\n",
        "tpr = dict()\n",
        "roc_auc = dict()\n",
        "\n",
        "for cur_class in range(n_classes):\n",
        "    fpr[cur_class], tpr[cur_class], _ = roc_curve(y_test[:, cur_class], y_pred_keras[:, cur_class ])  #, pos_label= 1)\n",
        "    roc_auc[cur_class] = auc(fpr[cur_class], tpr[cur_class])\n",
        "    print(roc_auc[cur_class])\n",
        "    plt.plot(fpr[cur_class],tpr[cur_class], marker='.', label='Class_0', color='b')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "Gq8GmJ57SRQo",
        "outputId": "ba6bf27b-72db-4dfb-df7b-3a87b3fe794a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0\n",
            "0.99\n",
            "1.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}